{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6fe564a-b9eb-42f3-aede-c00197c811c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "0            0.00               0.64           0.64           0.0   \n",
      "1            0.21               0.28           0.50           0.0   \n",
      "2            0.06               0.00           0.71           0.0   \n",
      "3            0.00               0.00           0.00           0.0   \n",
      "4            0.00               0.00           0.00           0.0   \n",
      "\n",
      "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "0           0.32            0.00              0.00                0.00   \n",
      "1           0.14            0.28              0.21                0.07   \n",
      "2           1.23            0.19              0.19                0.12   \n",
      "3           0.63            0.00              0.31                0.63   \n",
      "4           0.63            0.00              0.31                0.63   \n",
      "\n",
      "   word_freq_order  word_freq_mail  ...  char_freq_;   char_freq_(   \\\n",
      "0             0.00            0.00  ...          0.00         0.000   \n",
      "1             0.00            0.94  ...          0.00         0.132   \n",
      "2             0.64            0.25  ...          0.01         0.143   \n",
      "3             0.31            0.63  ...          0.00         0.137   \n",
      "4             0.31            0.63  ...          0.00         0.135   \n",
      "\n",
      "   char_freq_[   char_freq_!   char_freq_$   char_freq_#   \\\n",
      "0           0.0         0.778         0.000         0.000   \n",
      "1           0.0         0.372         0.180         0.048   \n",
      "2           0.0         0.276         0.184         0.010   \n",
      "3           0.0         0.137         0.000         0.000   \n",
      "4           0.0         0.135         0.000         0.000   \n",
      "\n",
      "    capital_run_length_average   capital_run_length_longest   \\\n",
      "0                         3.756                           61   \n",
      "1                         5.114                          101   \n",
      "2                         9.821                          485   \n",
      "3                         3.537                           40   \n",
      "4                         3.537                           40   \n",
      "\n",
      "    capital_run_length_total   spam  \n",
      "0                         278     1  \n",
      "1                        1028     1  \n",
      "2                        2259     1  \n",
      "3                         191     1  \n",
      "4                         191     1  \n",
      "\n",
      "[5 rows x 58 columns]\n",
      "\n",
      "Confusion Matrix:\n",
      "[[769  35]\n",
      " [ 71 506]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       804\n",
      "           1       0.94      0.88      0.91       577\n",
      "\n",
      "    accuracy                           0.92      1381\n",
      "   macro avg       0.93      0.92      0.92      1381\n",
      "weighted avg       0.92      0.92      0.92      1381\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "0.9232440260680667\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Load the dataset\n",
    "# Example dataset: UCI ML Spam dataset (simulated as CSV or you can download it)\n",
    "# For now, let's assume you have 'spam.csv' with the last column named 'spam' (1 = spam, 0 = not spam)\n",
    "df = pd.read_csv('spam.csv')\n",
    "\n",
    "# Preview the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# 2. Prepare features and labels\n",
    "X = df.drop('spam', axis=1)  # Features (drop the target column)\n",
    "y = df['spam']               # Target\n",
    "\n",
    "# 3. Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 4. Feature Scaling (important for Logistic Regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5. Train Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 6. Predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 7. Evaluation\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ceb097-0091-4354-882b-70f4e08196d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
